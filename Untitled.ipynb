{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob\n",
    "import numpy as np\n",
    "\n",
    "from PIL import Image, ImageDraw\n",
    "import scipy.ndimage.morphology as morph\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from args import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "with open('/storage/ProtopopovI/_data_/COCO/2014/annotations/person_keypoints_train2014.json') as data_file:    \n",
    "    data_json = json.load(data_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(data_json['images']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_json['annotations'][37502]['segmentation']\n",
    "# data_json['images'][80744]\n",
    "# data_json['annotations'][44474]#[37502]['segmentation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainPerson(Dataset):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.target_trans = transforms.Compose([\n",
    "            transforms.Resize((TARGET_SIZE, TARGET_SIZE), interpolation=0),\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "        self.search_trans = transforms.Compose([\n",
    "            transforms.Resize((SEARCH_SIZE, SEARCH_SIZE), interpolation=0),\n",
    "            transforms.ToTensor()\n",
    "            ])\n",
    "        self.file_names = sorted(os.listdir(\"/storage/ProtopopovI/_data_/COCO/2014/train2014/\"))\n",
    "        \n",
    "    def transform_score_label(self, depth2):\n",
    "        depth2 = depth2.reshape(1, 1, depth2.size(0), depth2.size(1))\n",
    "        max_value = depth2.max()\n",
    "        depth2 = (depth2 == max_value).float()\n",
    "        score_label = F.max_pool2d(depth2, kernel_size=(16, 16), padding=8, stride=16)\n",
    "        score_zero = (score_label == 0).float()\n",
    "        score_label = torch.stack([score_zero, score_label], dim=1).squeeze()\n",
    "        return score_label\n",
    "\n",
    "    def get_labels(self, object):\n",
    "        labels = torch.tensor([])\n",
    "        depths = torch.tensor([])\n",
    "        score_labels = torch.tensor([])\n",
    "        \n",
    "        label1 = (object==0).float()\n",
    "        depth1 = torch.tensor(morph.distance_transform_edt(np.asarray(label1[0])))\n",
    "        label2 = (label1==0).float()\n",
    "        depth2 = torch.tensor(morph.distance_transform_edt(np.asarray(label2[0])))\n",
    "        depth = (depth1 + depth2).float().unsqueeze(0)\n",
    "        label = torch.stack([label1, label2], dim=1)\n",
    "        labels = torch.cat([labels, label], dim=0)\n",
    "        depths = torch.cat([depths, depth], dim=0)\n",
    "        score_label = self.transform_score_label(depth2).unsqueeze(0)\n",
    "        score_labels = torch.cat([score_labels, score_label], dim=0)\n",
    "        labels = labels.squeeze()\n",
    "        \n",
    "        return labels, depths, score_labels\n",
    "    \n",
    "    def  __getitem__(self, idx):\n",
    "        file_name = self.file_names[idx]\n",
    "        \n",
    "        bboxs = []\n",
    "        seg_ids = []\n",
    "        js = []\n",
    "        for i in range(len(data_json['images'])):\n",
    "            if file_name == data_json['images'][i]['file_name']:\n",
    "                id = data_json['images'][i]['id']\n",
    "                image_i = i\n",
    "                for j in range(len(data_json['annotations'])):\n",
    "                    if id == data_json['annotations'][j]['image_id']:\n",
    "                        js.append(j)\n",
    "                        seg_ids.append(data_json['annotations'][j]['id'])\n",
    "                        bboxs.append(data_json['annotations'][j]['bbox'])\n",
    "        search = Image.open(\"/storage/ProtopopovI/_data_/COCO/2014/train2014/\" + file_name).convert('RGB')\n",
    "        \n",
    "        box = [bboxs[0][0], bboxs[0][1], bboxs[0][2], bboxs[0][3]]\n",
    "        size = [data_json['images'][image_i]['width'], data_json['images'][image_i]['height']]\n",
    "        center = [(box[0]+box[2]/2)/size[0], (box[1]+box[3]/2)/size[1]]\n",
    "        \n",
    "        \n",
    "        target = search.crop([box[0], box[1], box[0]+box[2], box[1]+box[3]])\n",
    "        \n",
    "        target = self.search_trans(target)\n",
    "        search = self.search_trans(search)\n",
    "        \n",
    "        mask = Image.new('L', (data_json['images'][image_i]['width'], data_json['images'][image_i]['height']))\n",
    "        idraw = ImageDraw.Draw(mask)\n",
    "        idraw.polygon(data_json['annotations'][js[0]]['segmentation'][0], fill='white')\n",
    "        mask = self.search_trans(mask)\n",
    "        label, depth, score_label = self.get_labels(mask)\n",
    "    \n",
    "        return target, search, label, depth, score_label, size, center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = TrainPerson()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "target, search, label, depth, score_label, size, center = data[130]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[480, 640]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6875729166666666, 0.63871875]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "center"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 256, 256])\n",
      "torch.Size([3, 256, 256])\n",
      "torch.Size([2, 256, 256])\n",
      "torch.Size([1, 256, 256])\n",
      "torch.Size([1, 2, 17, 17])\n"
     ]
    }
   ],
   "source": [
    "print(target.shape)\n",
    "print(search.shape)\n",
    "print(label.shape)\n",
    "print(depth.shape)\n",
    "print(score_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_label[0][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[13, 10]])\n"
     ]
    }
   ],
   "source": [
    "print((score_label[0][1] == 1).nonzero())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 32])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_32 = torch.rand([32, 32])\n",
    "t_32.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([34, 34])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "F.pad(t_32, [1,1,1,1]).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17+17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "68"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "17+17+17+17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
